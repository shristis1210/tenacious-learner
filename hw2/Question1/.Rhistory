library(foreach)
library(tidyverse)
library(class)
library(mosaic)
library(FNN)
sclass = read.csv('../data/sclass')
sclass350 = subset(sclass, trim == '350')
sclass65AMG = subset(sclass, trim == '65 AMG')
n350 = nrow(sclass350)
n_train350 = round(0.8*n350)
n_test350 = n350 - n_train350
train_cases350 = sample.int(n350, n_train350, replace=FALSE)
test_cases350 = setdiff(1:n350, train_cases350)
sclass350_train = sclass350[train_cases350,]
sclass350_test = sclass350[test_cases350,]
n65AMG = nrow(sclass65AMG)
n_train65AMG = round(0.8*n65AMG)
n_test65AMG = n65AMG - n_train65AMG
train_cases65AMG = sample.int(n65AMG, n_train65AMG, replace=FALSE)
test_cases65AMG = setdiff(1:n65AMG, train_cases65AMG)
sclass65AMG_train = sclass65AMG[train_cases65AMG,]
sclass65AMG_test = sclass65AMG[test_cases65AMG,]
Xtrain350 = model.matrix(~ mileage, data=sclass350_train)
Xtest350 = model.matrix(~ mileage, data=sclass350_test)
ytrain350 = sclass350_train$price
ytest350 = sclass350_test$price
Xtrain65AMG = model.matrix(~ mileage, data=sclass65AMG_train)
Xtest65AMG = model.matrix(~ mileage, data=sclass65AMG_test)
ytrain65AMG = sclass65AMG_train$price
ytest65AMG = sclass65AMG_test$price
K = 2
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
knn_model350 = knn.reg(Xtrain350, Xtest350, ytrain350, k=K)
rmse(ytest350, knn_model350$pred)
k_grid350 = exp(seq(log(1), log(300), length=100)) %>% round %>% unique
rmse_grid350 = foreach(K = k_grid350, .combine='c') %do% {
knn_model350 = knn.reg(Xtrain350, Xtest350, ytrain350, k=K)
rmse(ytest350, knn_model350$pred)
}
plot(k_grid350, rmse_grid350, log='x')
k_grid350[which.min(rmse_grid350)]
finalknn350 = knn.reg(train = Xtrain350, test = Xtest350, y = ytrain350, k=k_grid350[which.min(rmse_grid350)]
)
ypred_finalknn350 = finalknn350$pred
sclass350_test$ypred_finalknn350 = ypred_finalknn350
p_test = ggplot(data = sclass350_test) +
geom_point(mapping = aes(x = mileage, y = price), color='lightgrey')
p_test + geom_point(aes(x = mileage, y = ypred_finalknn350), color='red')
K =2
knn_model65AMG = knn.reg(Xtrain65AMG, Xtest65AMG, ytrain65AMG, k=K)
rmse(ytest65AMG, knn_model65AMG$pred)
k_grid65AMG = exp(seq(log(1), log(200), length=100)) %>% round %>% unique
rmse_grid65AMG = foreach(K = k_grid65AMG, .combine='c') %do% {
knn_model65AMG = knn.reg(Xtrain65AMG, Xtest65AMG, ytrain65AMG, k=K)
rmse(ytest65AMG, knn_model65AMG$pred)
}
plot(k_grid65AMG, rmse_grid65AMG, log='x')
k_grid65AMG[which.min(rmse_grid65AMG)]
finalknn65AMG = knn.reg(train = Xtrain65AMG, test = Xtest65AMG, y = ytrain65AMG, k=k_grid65AMG[which.min(rmse_grid65AMG)]
)
ypred_finalknn65AMG = finalknn65AMG$pred
sclass65AMG_test$ypred_finalknn65AMG = ypred_finalknn65AMG
p_test = ggplot(data = sclass65AMG_test) +
geom_point(mapping = aes(x = mileage, y = price), color='lightgrey')
p_test + geom_point(aes(x = mileage, y = ypred_finalknn65AMG), color='red')
n_train350 = round(0.8*n350)
library(foreach)
library(tidyverse)
library(class)
library(mosaic)
library(FNN)
sclass = read.csv('../data/sclass')
sclass350 = subset(sclass, trim == '350')
sclass65AMG = subset(sclass, trim == '65 AMG')
n350 = nrow(sclass350)
n_train350 = round(0.8*n350)
n_test350 = n350 - n_train350
train_cases350 = sample.int(n350, n_train350, replace=FALSE)
test_cases350 = setdiff(1:n350, train_cases350)
sclass350_train = sclass350[train_cases350,]
sclass350_test = sclass350[test_cases350,]
n65AMG = nrow(sclass65AMG)
n_train65AMG = round(0.8*n65AMG)
n_test65AMG = n65AMG - n_train65AMG
train_cases65AMG = sample.int(n65AMG, n_train65AMG, replace=FALSE)
test_cases65AMG = setdiff(1:n65AMG, train_cases65AMG)
sclass65AMG_train = sclass65AMG[train_cases65AMG,]
sclass65AMG_test = sclass65AMG[test_cases65AMG,]
Xtrain350 = model.matrix(~ mileage, data=sclass350_train)
Xtest350 = model.matrix(~ mileage, data=sclass350_test)
ytrain350 = sclass350_train$price
ytest350 = sclass350_test$price
Xtrain65AMG = model.matrix(~ mileage, data=sclass65AMG_train)
Xtest65AMG = model.matrix(~ mileage, data=sclass65AMG_test)
ytrain65AMG = sclass65AMG_train$price
ytest65AMG = sclass65AMG_test$price
K = 2
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
knn_model350 = knn.reg(Xtrain350, Xtest350, ytrain350, k=K)
rmse(ytest350, knn_model350$pred)
k_grid350 = exp(seq(log(1), log(300), length=100)) %>% round %>% unique
rmse_grid350 = foreach(K = k_grid350, .combine='c') %do% {
knn_model350 = knn.reg(Xtrain350, Xtest350, ytrain350, k=K)
rmse(ytest350, knn_model350$pred)
}
plot(k_grid350, rmse_grid350, log='x')
k_grid350[which.min(rmse_grid350)]
finalknn350 = knn.reg(train = Xtrain350, test = Xtest350, y = ytrain350, k=k_grid350[which.min(rmse_grid350)]
)
ypred_finalknn350 = finalknn350$pred
sclass350_test$ypred_finalknn350 = ypred_finalknn350
p_test = ggplot(data = sclass350_test) +
geom_point(mapping = aes(x = mileage, y = price), color='lightgrey')
p_test + geom_point(aes(x = mileage, y = ypred_finalknn350), color='red')
K =2
knn_model65AMG = knn.reg(Xtrain65AMG, Xtest65AMG, ytrain65AMG, k=K)
rmse(ytest65AMG, knn_model65AMG$pred)
k_grid65AMG = exp(seq(log(1), log(200), length=100)) %>% round %>% unique
rmse_grid65AMG = foreach(K = k_grid65AMG, .combine='c') %do% {
knn_model65AMG = knn.reg(Xtrain65AMG, Xtest65AMG, ytrain65AMG, k=K)
rmse(ytest65AMG, knn_model65AMG$pred)
}
plot(k_grid65AMG, rmse_grid65AMG, log='x')
k_grid65AMG[which.min(rmse_grid65AMG)]
finalknn65AMG = knn.reg(train = Xtrain65AMG, test = Xtest65AMG, y = ytrain65AMG, k=k_grid65AMG[which.min(rmse_grid65AMG)]
)
ypred_finalknn65AMG = finalknn65AMG$pred
sclass65AMG_test$ypred_finalknn65AMG = ypred_finalknn65AMG
p_test = ggplot(data = sclass65AMG_test) +
geom_point(mapping = aes(x = mileage, y = price), color='lightgrey')
p_test + geom_point(aes(x = mileage, y = ypred_finalknn65AMG), color='red')
library(foreach)
library(tidyverse)
library(class)
library(mosaic)
library(FNN)
sclass = read.csv('../data/sclass')
sclass350 = subset(sclass, trim == '350')
sclass65AMG = subset(sclass, trim == '65 AMG')
n350 = nrow(sclass350)
n_train350 = round(0.8*n350)
n_test350 = n350 - n_train350
train_cases350 = sample.int(n350, n_train350, replace=FALSE)
test_cases350 = setdiff(1:n350, train_cases350)
sclass350_train = sclass350[train_cases350,]
sclass350_test = sclass350[test_cases350,]
n65AMG = nrow(sclass65AMG)
n_train65AMG = round(0.8*n65AMG)
n_test65AMG = n65AMG - n_train65AMG
train_cases65AMG = sample.int(n65AMG, n_train65AMG, replace=FALSE)
test_cases65AMG = setdiff(1:n65AMG, train_cases65AMG)
sclass65AMG_train = sclass65AMG[train_cases65AMG,]
sclass65AMG_test = sclass65AMG[test_cases65AMG,]
Xtrain350 = model.matrix(~ mileage, data=sclass350_train)
Xtest350 = model.matrix(~ mileage, data=sclass350_test)
ytrain350 = sclass350_train$price
ytest350 = sclass350_test$price
Xtrain65AMG = model.matrix(~ mileage, data=sclass65AMG_train)
Xtest65AMG = model.matrix(~ mileage, data=sclass65AMG_test)
ytrain65AMG = sclass65AMG_train$price
ytest65AMG = sclass65AMG_test$price
K = 2
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
knn_model350 = knn.reg(Xtrain350, Xtest350, ytrain350, k=K)
rmse(ytest350, knn_model350$pred)
k_grid350 = exp(seq(log(1), log(300), length=100)) %>% round %>% unique
rmse_grid350 = foreach(K = k_grid350, .combine='c') %do% {
knn_model350 = knn.reg(Xtrain350, Xtest350, ytrain350, k=K)
rmse(ytest350, knn_model350$pred)
}
plot(k_grid350, rmse_grid350, log='x')
k_grid350[which.min(rmse_grid350)]
finalknn350 = knn.reg(train = Xtrain350, test = Xtest350, y = ytrain350, k=k_grid350[which.min(rmse_grid350)]
)
ypred_finalknn350 = finalknn350$pred
sclass350_test$ypred_finalknn350 = ypred_finalknn350
p_test = ggplot(data = sclass350_test) +
geom_point(mapping = aes(x = mileage, y = price), color='lightgrey')
p_test + geom_point(aes(x = mileage, y = ypred_finalknn350), color='red')
K =2
knn_model65AMG = knn.reg(Xtrain65AMG, Xtest65AMG, ytrain65AMG, k=K)
rmse(ytest65AMG, knn_model65AMG$pred)
k_grid65AMG = exp(seq(log(1), log(200), length=100)) %>% round %>% unique
rmse_grid65AMG = foreach(K = k_grid65AMG, .combine='c') %do% {
knn_model65AMG = knn.reg(Xtrain65AMG, Xtest65AMG, ytrain65AMG, k=K)
rmse(ytest65AMG, knn_model65AMG$pred)
}
plot(k_grid65AMG, rmse_grid65AMG, log='x')
k_grid65AMG[which.min(rmse_grid65AMG)]
finalknn65AMG = knn.reg(train = Xtrain65AMG, test = Xtest65AMG, y = ytrain65AMG, k=k_grid65AMG[which.min(rmse_grid65AMG)]
)
ypred_finalknn65AMG = finalknn65AMG$pred
sclass65AMG_test$ypred_finalknn65AMG = ypred_finalknn65AMG
p_test = ggplot(data = sclass65AMG_test) +
geom_point(mapping = aes(x = mileage, y = price), color='lightgrey')
p_test + geom_point(aes(x = mileage, y = ypred_finalknn65AMG), color='red')
sclass = read.csv('../data/sclass')
sclass <- read.csv("~/GitHub/SDS323_Spring2020/hw2/Question 1/sclass.csv")
View(sclass)
library(tidyverse, quietly = TRUE)
library(dplyr, quietly = TRUE)
library(mosaic, quietly = TRUE)
library(FNN, quietly = TRUE)
library(foreach, quietly = TRUE)
data(SaratogaHouses)
summary(SaratogaHouses)
#Defining models
# Baseline model
lm_small = lm(price ~ bedrooms + bathrooms + lotSize, data=SaratogaHouses)
# 11 main effects
lm_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
# Sometimes it's easier to name the variables we want to leave out
# The command below yields exactly the same model.
# the dot (.) means "all variables not named"
# the minus (-) means "exclude this variable"
lm_medium2 = lm(price ~ . - sewer - waterfront - landValue - newConstruction, data=SaratogaHouses)
coef(lm_medium)
coef(lm_medium2)
# All interactions
# the ()^2 says "include all pairwise interactions"
lm_big = lm(price ~ (. - sewer - waterfront - landValue - newConstruction)^2, data=SaratogaHouses)
####
# Compare out-of-sample predictive performance
####
# Split into training and testing sets
n = nrow(SaratogaHouses) # number of rows
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = SaratogaHouses[train_cases,]
saratoga_test = SaratogaHouses[test_cases,]
# Fit to the training data
lm1 = lm(price ~ lotSize + bedrooms + bathrooms, data=saratoga_train)
lm2 = lm(price ~ . - sewer - waterfront - landValue - newConstruction, data=saratoga_train)
lm3 = lm(price ~ (. - sewer - waterfront - landValue - newConstruction)^2, data=saratoga_train)
# Predictions out of sample
yhat_test1 = predict(lm1, saratoga_test)
yhat_test2 = predict(lm2, saratoga_test)
yhat_test3 = predict(lm3, saratoga_test)
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
# Root mean-squared prediction error
rmse(saratoga_test$price, yhat_test1)
rmse(saratoga_test$price, yhat_test2)
rmse(saratoga_test$price, yhat_test3)
# easy averaging over train/test splits
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
rmse_vals = do(100)*{
# re-split into train and test cases with the same sample sizes
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = SaratogaHouses[train_cases,]
saratoga_test = SaratogaHouses[test_cases,]
# Fit to the training data
lm1 = lm(price ~ lotSize + bedrooms + bathrooms, data=saratoga_train)
lm2 = lm(price ~ . - sewer - waterfront - landValue - newConstruction, data=saratoga_train)
lm3 = lm(price ~ (. - sewer - waterfront - landValue - newConstruction)^2, data=saratoga_train)
lm_dominate = lm(price ~ lotSize + age + livingArea + pctCollege +
bedrooms + fireplaces + bathrooms + rooms + heating + fuel +
centralAir + lotSize:heating + livingArea:rooms + newConstruction + livingArea:newConstruction, data=saratoga_train)
# Predictions out of sample
yhat_test1 = predict(lm1, saratoga_test)
yhat_test2 = predict(lm2, saratoga_test)
yhat_test3 = predict(lm3, saratoga_test)
yhat_test4 = predict(lm_dominate, saratoga_test)
c(rmse(saratoga_test$price, yhat_test1),
rmse(saratoga_test$price, yhat_test2),
rmse(saratoga_test$price, yhat_test3),
rmse(saratoga_test$price, yhat_test4))
}
rmse_vals
colMeans(rmse_vals)
boxplot(rmse_vals)
str(SaratogaHouses)
# New variables for "hand-built" model
SaratogaHouses$ConstructionCost <- SaratogaHouses$price - SaratogaHouses$landValue
SaratogaHouses$waterfrontDummy <- ifelse(SaratogaHouses$waterfront == "yes", 1,0)
SaratogaHouses$newConstructionDummy <- ifelse(SaratogaHouses$age == "yes", 1,0)
SaratogaHouses$centralAirDummy <- ifelse(SaratogaHouses$age == "yes", 1,0)
str(SaratogaHouses)
HeatingElectric <- SaratogaHouses[grep("electric", SaratogaHouses$heating), ]
#View(HeatingElectric)
#str(HeatingElectric)
HeatingSteam <- SaratogaHouses[grep("hot water/steam", SaratogaHouses$heating), ]
#View(HeatingSteam)
#str(HeatingSteam)
HeatingHotAir <- SaratogaHouses[grep("hot air", SaratogaHouses$heating), ]
#View(HeatingHotAir)
#str(HeatingHotAir)
FuelOil <- SaratogaHouses[grep("oil", SaratogaHouses$fuel), ]
#View(FuelOil)
#str(FuelOil)
FuelGas <- SaratogaHouses[grep("gas", SaratogaHouses$fuel), ]
#View(FuelGas)
#str(FuelGas)
FuelElectric <- SaratogaHouses[grep("electric", SaratogaHouses$fuel), ]
#View(FuelElectric)
#str(FuelElectric)
SewerSeptic <- SaratogaHouses[grep("septic", SaratogaHouses$sewer), ]
#View(SewerSeptic)
#str(SewerSeptic)
SewerPublicCommercial <- SaratogaHouses[grep("public/commercial", SaratogaHouses$sewer), ]
#View(SewerPublicCommercial)
#str(SewerPublicCommercial)
SewerNone <- SaratogaHouses[grep("none", SaratogaHouses$sewer), ]
#View(SewerNone)
#str(SewerNone)
#Defining the models
#Baseline model
lm_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
#Hand-built Model
lm_handbuilt = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir + ConstructionCost +
ConstructionCost*landValue + newConstructionDummy*landValue + newConstructionDummy*lotSize +
pctCollege*age + bathrooms*bedrooms, data = SaratogaHouses)
#Defining only the numerics of the train-test data sets
N = nrow(SaratogaHouses)
train = round(0.8*N)
test = (N-train)
#Defining the function
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
#Rmse iterations
rmse1 <- NULL
rmse2 <- NULL
for (i in seq(1:00)){
#Choosing data for training and testing
train_cases = sample.int(N, train, replace=FALSE)
test_cases = setdiff(1:N, train_cases)
#Define the train-test data sets (for all X's and Y)
saratoga_train = SaratogaHouses[train_cases,]
saratoga_test = SaratogaHouses[test_cases,]
#Training
#Baseline model
lm_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=saratoga_train)
#Hand-built Model
lm_handbuilt = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir + ConstructionCost +
ConstructionCost*landValue + newConstructionDummy*landValue + newConstructionDummy*lotSize +
pctCollege*age + bathrooms*bedrooms, data = saratoga_train)
#Testing
yhat_test1 = predict(lm_medium, saratoga_test)
yhat_test2 = predict(lm_handbuilt, saratoga_test)
#Run it on the actual and the predicted values
rmse1[i]= rmse(saratoga_test$price, yhat_test1)
rmse2[i]= rmse(saratoga_test$price, yhat_test2)
}
mean(rmse1)
mean(rmse2)
# K-Nearest Neighbors Model
#Defining train-test sets for the hand-built regression model
KNNModel = do(100)*{
N = nrow(SaratogaHouses)
train = round(0.8*N)
test = (N-train)
train_cases = sample.int(N, train, replace=FALSE)
test_cases = setdiff(1:N, train_cases)
saratoga_train = SaratogaHouses[train_cases,]
saratoga_test = SaratogaHouses[test_cases,]
Xtrain = model.matrix(~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir + ConstructionCost
- 1, data=saratoga_train)
Xtest = model.matrix(~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir + ConstructionCost
- 1, data=saratoga_test)
Ytrain = saratoga_train$price
Ytest = saratoga_test$price
#Scaling the features (Standardization)
scale_train = apply(Xtrain, 2, sd)
Xtilde_train = scale(Xtrain, scale = scale_train)
Xtilde_test = scale(Xtest, scale = scale_train)
#The for loop
k_grid = seq(2,100)
rmse_grid = foreach(K = k_grid, .combine='c') %do% {
KNNModel = knn.reg(Xtilde_train, Xtilde_test, Ytrain, k=K)
rmse(Ytest, KNNModel$pred)
}
}
KNNModelMean = colMeans(KNNModel)
#Plotting
plot(k_grid, KNNModelMean)
abline(h=rmse(Ytest, yhat_test2))
library(rmarkdown)
rmarkdown::render("question1.Rmd")
